{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import libraries and modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras import regularizers, optimizers\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = pd.read_csv('./train.csv')\n",
    "val = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = inputs.label\n",
    "data = inputs.drop(labels = 'label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data,labels,test_size=(0.2),random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val = val.values.reshape(-1,28,28,1)\n",
    "X_val = X_val.astype('float32')\n",
    "X_val /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33600, 784)\n",
      "(33600, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# 3. Preprocess input data\n",
    "\n",
    "print(X_train.shape)\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "X_test = X_test.values.reshape(-1,28,28,1)\n",
    "print(X_train.shape)\n",
    "      \n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. Preprocess class labels\n",
    "y_train_cat = np_utils.to_categorical(y_train, 10)\n",
    "y_test_cat = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33600"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = image.ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=5,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image \n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(lr=0.0001)\n",
    "\n",
    "\n",
    "# 5. Model Architecture\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(filters = 16, \n",
    "                        kernel_size = 5,\n",
    "                       activation = 'relu', \n",
    "                        input_shape = (28,28,1)))\n",
    "model.add(Convolution2D(filters = 16, \n",
    "                        kernel_size = 5,\n",
    "                        padding = 'same',\n",
    "                       activation = 'relu',\n",
    "                        input_shape = (28,28,1)))\n",
    "model.add(Convolution2D(filters = 16, \n",
    "                        kernel_size = 5,\n",
    "                        padding = 'same',\n",
    "                       activation = 'relu',\n",
    "                        input_shape = (28,28,1)))\n",
    "model.add(MaxPooling2D( pool_size= (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(filters = 8, \n",
    "                        kernel_size = 3,\n",
    "                        padding = 'same',\n",
    "                       activation = 'relu'))\n",
    "model.add(Convolution2D(filters = 8, \n",
    "                        kernel_size = 3,\n",
    "                        padding = 'same',\n",
    "                       activation = 'relu'))\n",
    "model.add(Convolution2D(filters = 8, \n",
    "                        kernel_size = 3,\n",
    "                        padding = 'same',\n",
    "                       activation = 'relu'))\n",
    "model.add(MaxPooling2D( pool_size= (2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(64, \n",
    "                activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, \n",
    "                activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(10, \n",
    "                activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6. Compile Model\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "             optimizer = adam)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=50, mode='auto')\n",
    "callbacks_list = [early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/600\n",
      "33600/33600 [==============================] - 90s 3ms/step - loss: 2.1389 - acc: 0.2160 - val_loss: 1.3099 - val_acc: 0.7661\n",
      "Epoch 2/600\n",
      "33600/33600 [==============================] - 68s 2ms/step - loss: 1.2519 - acc: 0.5852 - val_loss: 0.4806 - val_acc: 0.8736\n",
      "Epoch 3/600\n",
      "33600/33600 [==============================] - 67s 2ms/step - loss: 0.8023 - acc: 0.7362 - val_loss: 0.3230 - val_acc: 0.9137\n",
      "Epoch 4/600\n",
      "33600/33600 [==============================] - 67s 2ms/step - loss: 0.6114 - acc: 0.8020 - val_loss: 0.2471 - val_acc: 0.9336\n",
      "Epoch 5/600\n",
      "33600/33600 [==============================] - 67s 2ms/step - loss: 0.5085 - acc: 0.8374 - val_loss: 0.2130 - val_acc: 0.9406\n",
      "Epoch 6/600\n",
      "33600/33600 [==============================] - 67s 2ms/step - loss: 0.4496 - acc: 0.8591 - val_loss: 0.1801 - val_acc: 0.9482\n",
      "Epoch 7/600\n",
      "33600/33600 [==============================] - 68s 2ms/step - loss: 0.3998 - acc: 0.8754 - val_loss: 0.1632 - val_acc: 0.9531\n",
      "Epoch 8/600\n",
      "33600/33600 [==============================] - 67s 2ms/step - loss: 0.3607 - acc: 0.8885 - val_loss: 0.1571 - val_acc: 0.9542\n",
      "Epoch 9/600\n",
      "33600/33600 [==============================] - 67s 2ms/step - loss: 0.3351 - acc: 0.8968 - val_loss: 0.1400 - val_acc: 0.9573\n",
      "Epoch 10/600\n",
      "33600/33600 [==============================] - 67s 2ms/step - loss: 0.3095 - acc: 0.9033 - val_loss: 0.1310 - val_acc: 0.9595\n",
      "Epoch 11/600\n",
      "33600/33600 [==============================] - 72s 2ms/step - loss: 0.2932 - acc: 0.9127 - val_loss: 0.1233 - val_acc: 0.9610\n",
      "Epoch 12/600\n",
      "33600/33600 [==============================] - 73s 2ms/step - loss: 0.2756 - acc: 0.9168 - val_loss: 0.1177 - val_acc: 0.9645\n",
      "Epoch 13/600\n",
      "33600/33600 [==============================] - 81s 2ms/step - loss: 0.2553 - acc: 0.9220 - val_loss: 0.1108 - val_acc: 0.9648\n",
      "Epoch 14/600\n",
      "33600/33600 [==============================] - 84s 3ms/step - loss: 0.2482 - acc: 0.9261 - val_loss: 0.1053 - val_acc: 0.9674\n",
      "Epoch 15/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.2372 - acc: 0.9287 - val_loss: 0.1025 - val_acc: 0.9692\n",
      "Epoch 16/600\n",
      "33600/33600 [==============================] - 74s 2ms/step - loss: 0.2262 - acc: 0.9320 - val_loss: 0.0984 - val_acc: 0.9690\n",
      "Epoch 17/600\n",
      "33600/33600 [==============================] - 72s 2ms/step - loss: 0.2251 - acc: 0.9341 - val_loss: 0.0961 - val_acc: 0.9702\n",
      "Epoch 18/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.2156 - acc: 0.9360 - val_loss: 0.0936 - val_acc: 0.9712\n",
      "Epoch 19/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.2029 - acc: 0.9405 - val_loss: 0.0895 - val_acc: 0.9735\n",
      "Epoch 20/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.1979 - acc: 0.9422 - val_loss: 0.0869 - val_acc: 0.9730\n",
      "Epoch 21/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.1888 - acc: 0.9439 - val_loss: 0.0842 - val_acc: 0.9751\n",
      "Epoch 22/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.1865 - acc: 0.9449 - val_loss: 0.0806 - val_acc: 0.9746\n",
      "Epoch 23/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.1808 - acc: 0.9445 - val_loss: 0.0779 - val_acc: 0.9762\n",
      "Epoch 24/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.1747 - acc: 0.9493 - val_loss: 0.0775 - val_acc: 0.9768\n",
      "Epoch 25/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.1659 - acc: 0.9513 - val_loss: 0.0782 - val_acc: 0.9771\n",
      "Epoch 26/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.1599 - acc: 0.9525 - val_loss: 0.0730 - val_acc: 0.9780\n",
      "Epoch 27/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.1574 - acc: 0.9538 - val_loss: 0.0714 - val_acc: 0.9788\n",
      "Epoch 28/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.1545 - acc: 0.9543 - val_loss: 0.0708 - val_acc: 0.9782\n",
      "Epoch 29/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.1520 - acc: 0.9556 - val_loss: 0.0738 - val_acc: 0.9779\n",
      "Epoch 30/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.1483 - acc: 0.9566 - val_loss: 0.0654 - val_acc: 0.9808\n",
      "Epoch 31/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.1445 - acc: 0.9589 - val_loss: 0.0652 - val_acc: 0.9800\n",
      "Epoch 32/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.1403 - acc: 0.9588 - val_loss: 0.0643 - val_acc: 0.9814\n",
      "Epoch 33/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.1384 - acc: 0.9601 - val_loss: 0.0632 - val_acc: 0.9810\n",
      "Epoch 34/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.1366 - acc: 0.9604 - val_loss: 0.0643 - val_acc: 0.9819\n",
      "Epoch 35/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.1356 - acc: 0.9614 - val_loss: 0.0639 - val_acc: 0.9823\n",
      "Epoch 36/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.1304 - acc: 0.9629 - val_loss: 0.0593 - val_acc: 0.9832\n",
      "Epoch 37/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.1310 - acc: 0.9621 - val_loss: 0.0586 - val_acc: 0.9824\n",
      "Epoch 38/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.1241 - acc: 0.9642 - val_loss: 0.0626 - val_acc: 0.9830\n",
      "Epoch 39/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.1238 - acc: 0.9634 - val_loss: 0.0578 - val_acc: 0.9829\n",
      "Epoch 40/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.1241 - acc: 0.9649 - val_loss: 0.0567 - val_acc: 0.9832\n",
      "Epoch 41/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.1237 - acc: 0.9643 - val_loss: 0.0561 - val_acc: 0.9821\n",
      "Epoch 42/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.1187 - acc: 0.9656 - val_loss: 0.0559 - val_acc: 0.9836\n",
      "Epoch 43/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.1213 - acc: 0.9657 - val_loss: 0.0538 - val_acc: 0.9842\n",
      "Epoch 44/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.1175 - acc: 0.9657 - val_loss: 0.0551 - val_acc: 0.9839\n",
      "Epoch 45/600\n",
      "33600/33600 [==============================] - 67s 2ms/step - loss: 0.1116 - acc: 0.9686 - val_loss: 0.0535 - val_acc: 0.9830\n",
      "Epoch 46/600\n",
      "33600/33600 [==============================] - 128s 4ms/step - loss: 0.1079 - acc: 0.9697 - val_loss: 0.0537 - val_acc: 0.9843\n",
      "Epoch 47/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.1104 - acc: 0.9686 - val_loss: 0.0521 - val_acc: 0.9845\n",
      "Epoch 48/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.1065 - acc: 0.9690 - val_loss: 0.0516 - val_acc: 0.9848\n",
      "Epoch 49/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.1089 - acc: 0.9683 - val_loss: 0.0524 - val_acc: 0.9849\n",
      "Epoch 50/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.1077 - acc: 0.9691 - val_loss: 0.0490 - val_acc: 0.9848\n",
      "Epoch 51/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.1036 - acc: 0.9697 - val_loss: 0.0519 - val_acc: 0.9848\n",
      "Epoch 52/600\n",
      "33600/33600 [==============================] - 78s 2ms/step - loss: 0.1015 - acc: 0.9702 - val_loss: 0.0497 - val_acc: 0.9849\n",
      "Epoch 53/600\n",
      "33600/33600 [==============================] - 74s 2ms/step - loss: 0.0996 - acc: 0.9720 - val_loss: 0.0537 - val_acc: 0.9839\n",
      "Epoch 54/600\n",
      "33600/33600 [==============================] - 74s 2ms/step - loss: 0.1041 - acc: 0.9696 - val_loss: 0.0479 - val_acc: 0.9855\n",
      "Epoch 55/600\n",
      "33600/33600 [==============================] - 74s 2ms/step - loss: 0.1003 - acc: 0.9716 - val_loss: 0.0486 - val_acc: 0.9857\n",
      "Epoch 56/600\n",
      "33600/33600 [==============================] - 74s 2ms/step - loss: 0.0984 - acc: 0.9723 - val_loss: 0.0481 - val_acc: 0.9858\n",
      "Epoch 57/600\n",
      "33600/33600 [==============================] - 74s 2ms/step - loss: 0.0940 - acc: 0.9726 - val_loss: 0.0493 - val_acc: 0.9865\n",
      "Epoch 58/600\n",
      "33600/33600 [==============================] - 69s 2ms/step - loss: 0.0950 - acc: 0.9731 - val_loss: 0.0458 - val_acc: 0.9862\n",
      "Epoch 59/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0954 - acc: 0.9735 - val_loss: 0.0456 - val_acc: 0.9863\n",
      "Epoch 60/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0899 - acc: 0.9743 - val_loss: 0.0464 - val_acc: 0.9865\n",
      "Epoch 61/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0901 - acc: 0.9728 - val_loss: 0.0459 - val_acc: 0.9863\n",
      "Epoch 62/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0951 - acc: 0.9736 - val_loss: 0.0448 - val_acc: 0.9863\n",
      "Epoch 63/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0910 - acc: 0.9741 - val_loss: 0.0447 - val_acc: 0.9867\n",
      "Epoch 64/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0893 - acc: 0.9749 - val_loss: 0.0427 - val_acc: 0.9863\n",
      "Epoch 65/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0844 - acc: 0.9757 - val_loss: 0.0460 - val_acc: 0.9863\n",
      "Epoch 66/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0882 - acc: 0.9745 - val_loss: 0.0447 - val_acc: 0.9867\n",
      "Epoch 67/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0839 - acc: 0.9748 - val_loss: 0.0483 - val_acc: 0.9858\n",
      "Epoch 68/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0847 - acc: 0.9764 - val_loss: 0.0426 - val_acc: 0.9871\n",
      "Epoch 69/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0811 - acc: 0.9761 - val_loss: 0.0417 - val_acc: 0.9871\n",
      "Epoch 70/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0823 - acc: 0.9759 - val_loss: 0.0453 - val_acc: 0.9855\n",
      "Epoch 71/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0836 - acc: 0.9760 - val_loss: 0.0409 - val_acc: 0.9877\n",
      "Epoch 72/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0803 - acc: 0.9766 - val_loss: 0.0391 - val_acc: 0.9871\n",
      "Epoch 73/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0799 - acc: 0.9772 - val_loss: 0.0396 - val_acc: 0.9882\n",
      "Epoch 74/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0833 - acc: 0.9754 - val_loss: 0.0403 - val_acc: 0.9870\n",
      "Epoch 75/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0807 - acc: 0.9772 - val_loss: 0.0427 - val_acc: 0.9869\n",
      "Epoch 76/600\n",
      "33600/33600 [==============================] - 67s 2ms/step - loss: 0.0810 - acc: 0.9774 - val_loss: 0.0414 - val_acc: 0.9867\n",
      "Epoch 77/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0781 - acc: 0.9774 - val_loss: 0.0404 - val_acc: 0.9876\n",
      "Epoch 78/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0770 - acc: 0.9772 - val_loss: 0.0417 - val_acc: 0.9868\n",
      "Epoch 79/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0779 - acc: 0.9780 - val_loss: 0.0382 - val_acc: 0.9881\n",
      "Epoch 80/600\n",
      "33600/33600 [==============================] - 67s 2ms/step - loss: 0.0755 - acc: 0.9780 - val_loss: 0.0372 - val_acc: 0.9885\n",
      "Epoch 81/600\n",
      "33600/33600 [==============================] - 73s 2ms/step - loss: 0.0772 - acc: 0.9783 - val_loss: 0.0401 - val_acc: 0.9876\n",
      "Epoch 82/600\n",
      "33600/33600 [==============================] - 72s 2ms/step - loss: 0.0754 - acc: 0.9788 - val_loss: 0.0380 - val_acc: 0.9882\n",
      "Epoch 83/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0749 - acc: 0.9779 - val_loss: 0.0382 - val_acc: 0.9887\n",
      "Epoch 84/600\n",
      "33600/33600 [==============================] - 129s 4ms/step - loss: 0.0729 - acc: 0.9788 - val_loss: 0.0381 - val_acc: 0.9885\n",
      "Epoch 85/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0720 - acc: 0.9790 - val_loss: 0.0412 - val_acc: 0.9880\n",
      "Epoch 86/600\n",
      "33600/33600 [==============================] - 129s 4ms/step - loss: 0.0709 - acc: 0.9793 - val_loss: 0.0423 - val_acc: 0.9880\n",
      "Epoch 87/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0725 - acc: 0.9796 - val_loss: 0.0413 - val_acc: 0.9886\n",
      "Epoch 88/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0710 - acc: 0.9795 - val_loss: 0.0366 - val_acc: 0.9885\n",
      "Epoch 89/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0700 - acc: 0.9803 - val_loss: 0.0383 - val_acc: 0.9887\n",
      "Epoch 90/600\n",
      "33600/33600 [==============================] - 129s 4ms/step - loss: 0.0679 - acc: 0.9800 - val_loss: 0.0371 - val_acc: 0.9890\n",
      "Epoch 91/600\n",
      "33600/33600 [==============================] - 129s 4ms/step - loss: 0.0703 - acc: 0.9799 - val_loss: 0.0359 - val_acc: 0.9890\n",
      "Epoch 92/600\n",
      "33600/33600 [==============================] - 131s 4ms/step - loss: 0.0694 - acc: 0.9797 - val_loss: 0.0353 - val_acc: 0.9890\n",
      "Epoch 93/600\n",
      "33600/33600 [==============================] - 131s 4ms/step - loss: 0.0696 - acc: 0.9807 - val_loss: 0.0367 - val_acc: 0.9885\n",
      "Epoch 94/600\n",
      "33600/33600 [==============================] - 131s 4ms/step - loss: 0.0672 - acc: 0.9804 - val_loss: 0.0376 - val_acc: 0.9887\n",
      "Epoch 95/600\n",
      "33600/33600 [==============================] - 131s 4ms/step - loss: 0.0680 - acc: 0.9800 - val_loss: 0.0357 - val_acc: 0.9890\n",
      "Epoch 96/600\n",
      "33600/33600 [==============================] - 131s 4ms/step - loss: 0.0689 - acc: 0.9798 - val_loss: 0.0369 - val_acc: 0.9885\n",
      "Epoch 97/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0677 - acc: 0.9802 - val_loss: 0.0404 - val_acc: 0.9875\n",
      "Epoch 98/600\n",
      "33600/33600 [==============================] - 132s 4ms/step - loss: 0.0662 - acc: 0.9804 - val_loss: 0.0380 - val_acc: 0.9886\n",
      "Epoch 99/600\n",
      "33600/33600 [==============================] - 131s 4ms/step - loss: 0.0654 - acc: 0.9801 - val_loss: 0.0379 - val_acc: 0.9890\n",
      "Epoch 100/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0641 - acc: 0.9815 - val_loss: 0.0375 - val_acc: 0.9886\n",
      "Epoch 101/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0619 - acc: 0.9821 - val_loss: 0.0366 - val_acc: 0.9892\n",
      "Epoch 102/600\n",
      "33600/33600 [==============================] - 131s 4ms/step - loss: 0.0663 - acc: 0.9809 - val_loss: 0.0342 - val_acc: 0.9896\n",
      "Epoch 103/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0663 - acc: 0.9808 - val_loss: 0.0366 - val_acc: 0.9893\n",
      "Epoch 104/600\n",
      "33600/33600 [==============================] - 131s 4ms/step - loss: 0.0648 - acc: 0.9809 - val_loss: 0.0366 - val_acc: 0.9893\n",
      "Epoch 105/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0624 - acc: 0.9817 - val_loss: 0.0350 - val_acc: 0.9890\n",
      "Epoch 106/600\n",
      "33600/33600 [==============================] - 131s 4ms/step - loss: 0.0661 - acc: 0.9809 - val_loss: 0.0357 - val_acc: 0.9899\n",
      "Epoch 107/600\n",
      "33600/33600 [==============================] - 131s 4ms/step - loss: 0.0633 - acc: 0.9817 - val_loss: 0.0341 - val_acc: 0.9893\n",
      "Epoch 108/600\n",
      "33600/33600 [==============================] - 131s 4ms/step - loss: 0.0627 - acc: 0.9816 - val_loss: 0.0339 - val_acc: 0.9890\n",
      "Epoch 109/600\n",
      "33600/33600 [==============================] - 131s 4ms/step - loss: 0.0597 - acc: 0.9825 - val_loss: 0.0335 - val_acc: 0.9896\n",
      "Epoch 110/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0595 - acc: 0.9824 - val_loss: 0.0346 - val_acc: 0.9899\n",
      "Epoch 111/600\n",
      "33600/33600 [==============================] - 131s 4ms/step - loss: 0.0593 - acc: 0.9831 - val_loss: 0.0350 - val_acc: 0.9888\n",
      "Epoch 112/600\n",
      "33600/33600 [==============================] - 131s 4ms/step - loss: 0.0583 - acc: 0.9829 - val_loss: 0.0359 - val_acc: 0.9894\n",
      "Epoch 113/600\n",
      "33600/33600 [==============================] - 131s 4ms/step - loss: 0.0616 - acc: 0.9826 - val_loss: 0.0364 - val_acc: 0.9900\n",
      "Epoch 114/600\n",
      "33600/33600 [==============================] - 131s 4ms/step - loss: 0.0613 - acc: 0.9823 - val_loss: 0.0336 - val_acc: 0.9900\n",
      "Epoch 115/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0594 - acc: 0.9833 - val_loss: 0.0357 - val_acc: 0.9895\n",
      "Epoch 116/600\n",
      "33600/33600 [==============================] - 131s 4ms/step - loss: 0.0604 - acc: 0.9827 - val_loss: 0.0351 - val_acc: 0.9899\n",
      "Epoch 117/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0609 - acc: 0.9825 - val_loss: 0.0352 - val_acc: 0.9890\n",
      "Epoch 118/600\n",
      "33600/33600 [==============================] - 129s 4ms/step - loss: 0.0577 - acc: 0.9840 - val_loss: 0.0333 - val_acc: 0.9894\n",
      "Epoch 119/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0605 - acc: 0.9820 - val_loss: 0.0345 - val_acc: 0.9890\n",
      "Epoch 120/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0572 - acc: 0.9823 - val_loss: 0.0329 - val_acc: 0.9902\n",
      "Epoch 121/600\n",
      "33600/33600 [==============================] - 129s 4ms/step - loss: 0.0575 - acc: 0.9834 - val_loss: 0.0334 - val_acc: 0.9895\n",
      "Epoch 122/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0562 - acc: 0.9842 - val_loss: 0.0350 - val_acc: 0.9890\n",
      "Epoch 123/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0572 - acc: 0.9828 - val_loss: 0.0341 - val_acc: 0.9902\n",
      "Epoch 124/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0583 - acc: 0.9824 - val_loss: 0.0338 - val_acc: 0.9904\n",
      "Epoch 125/600\n",
      "33600/33600 [==============================] - 129s 4ms/step - loss: 0.0573 - acc: 0.9830 - val_loss: 0.0345 - val_acc: 0.9901\n",
      "Epoch 126/600\n",
      "33600/33600 [==============================] - 131s 4ms/step - loss: 0.0530 - acc: 0.9847 - val_loss: 0.0334 - val_acc: 0.9904\n",
      "Epoch 127/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0575 - acc: 0.9840 - val_loss: 0.0353 - val_acc: 0.9898\n",
      "Epoch 128/600\n",
      "33600/33600 [==============================] - 131s 4ms/step - loss: 0.0534 - acc: 0.9843 - val_loss: 0.0339 - val_acc: 0.9905\n",
      "Epoch 129/600\n",
      "33600/33600 [==============================] - 131s 4ms/step - loss: 0.0536 - acc: 0.9841 - val_loss: 0.0322 - val_acc: 0.9904\n",
      "Epoch 130/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0556 - acc: 0.9835 - val_loss: 0.0353 - val_acc: 0.9902\n",
      "Epoch 131/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0541 - acc: 0.9840 - val_loss: 0.0335 - val_acc: 0.9895\n",
      "Epoch 132/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0562 - acc: 0.9834 - val_loss: 0.0340 - val_acc: 0.9901\n",
      "Epoch 133/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0550 - acc: 0.9833 - val_loss: 0.0318 - val_acc: 0.9901\n",
      "Epoch 134/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0525 - acc: 0.9848 - val_loss: 0.0337 - val_acc: 0.9907\n",
      "Epoch 135/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0535 - acc: 0.9845 - val_loss: 0.0327 - val_acc: 0.9908\n",
      "Epoch 136/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0534 - acc: 0.9847 - val_loss: 0.0325 - val_acc: 0.9910\n",
      "Epoch 137/600\n",
      "33600/33600 [==============================] - 131s 4ms/step - loss: 0.0533 - acc: 0.9849 - val_loss: 0.0335 - val_acc: 0.9905\n",
      "Epoch 138/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0510 - acc: 0.9855 - val_loss: 0.0321 - val_acc: 0.9906\n",
      "Epoch 139/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0536 - acc: 0.9839 - val_loss: 0.0326 - val_acc: 0.9901\n",
      "Epoch 140/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0503 - acc: 0.9851 - val_loss: 0.0334 - val_acc: 0.9908\n",
      "Epoch 141/600\n",
      "33600/33600 [==============================] - 118s 4ms/step - loss: 0.0540 - acc: 0.9834 - val_loss: 0.0336 - val_acc: 0.9904\n",
      "Epoch 142/600\n",
      "33600/33600 [==============================] - 78s 2ms/step - loss: 0.0540 - acc: 0.9839 - val_loss: 0.0325 - val_acc: 0.9908\n",
      "Epoch 143/600\n",
      "33600/33600 [==============================] - 78s 2ms/step - loss: 0.0499 - acc: 0.9857 - val_loss: 0.0337 - val_acc: 0.9908\n",
      "Epoch 144/600\n",
      "33600/33600 [==============================] - 78s 2ms/step - loss: 0.0513 - acc: 0.9851 - val_loss: 0.0329 - val_acc: 0.9912\n",
      "Epoch 145/600\n",
      "33600/33600 [==============================] - 78s 2ms/step - loss: 0.0505 - acc: 0.9850 - val_loss: 0.0328 - val_acc: 0.9906\n",
      "Epoch 146/600\n",
      "33600/33600 [==============================] - 78s 2ms/step - loss: 0.0508 - acc: 0.9849 - val_loss: 0.0356 - val_acc: 0.9905\n",
      "Epoch 147/600\n",
      "33600/33600 [==============================] - 78s 2ms/step - loss: 0.0502 - acc: 0.9847 - val_loss: 0.0366 - val_acc: 0.9905\n",
      "Epoch 148/600\n",
      "33600/33600 [==============================] - 76s 2ms/step - loss: 0.0514 - acc: 0.9843 - val_loss: 0.0349 - val_acc: 0.9904\n",
      "Epoch 149/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0483 - acc: 0.9859 - val_loss: 0.0334 - val_acc: 0.9911\n",
      "Epoch 150/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0498 - acc: 0.9851 - val_loss: 0.0333 - val_acc: 0.9912\n",
      "Epoch 151/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0500 - acc: 0.9856 - val_loss: 0.0326 - val_acc: 0.9906\n",
      "Epoch 152/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0494 - acc: 0.9854 - val_loss: 0.0350 - val_acc: 0.9904\n",
      "Epoch 153/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0498 - acc: 0.9847 - val_loss: 0.0319 - val_acc: 0.9905\n",
      "Epoch 154/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0481 - acc: 0.9856 - val_loss: 0.0352 - val_acc: 0.9912\n",
      "Epoch 155/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0498 - acc: 0.9847 - val_loss: 0.0312 - val_acc: 0.9911\n",
      "Epoch 156/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0463 - acc: 0.9863 - val_loss: 0.0329 - val_acc: 0.9912\n",
      "Epoch 157/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0466 - acc: 0.9860 - val_loss: 0.0400 - val_acc: 0.9895\n",
      "Epoch 158/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0474 - acc: 0.9867 - val_loss: 0.0322 - val_acc: 0.9912\n",
      "Epoch 159/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0488 - acc: 0.9857 - val_loss: 0.0313 - val_acc: 0.9914\n",
      "Epoch 160/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0475 - acc: 0.9859 - val_loss: 0.0329 - val_acc: 0.9907\n",
      "Epoch 161/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0478 - acc: 0.9858 - val_loss: 0.0359 - val_acc: 0.9912\n",
      "Epoch 162/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0483 - acc: 0.9855 - val_loss: 0.0331 - val_acc: 0.9908\n",
      "Epoch 163/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0454 - acc: 0.9866 - val_loss: 0.0335 - val_acc: 0.9907\n",
      "Epoch 164/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0464 - acc: 0.9863 - val_loss: 0.0363 - val_acc: 0.9904\n",
      "Epoch 165/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0459 - acc: 0.9864 - val_loss: 0.0327 - val_acc: 0.9912\n",
      "Epoch 166/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0465 - acc: 0.9863 - val_loss: 0.0328 - val_acc: 0.9911\n",
      "Epoch 167/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0462 - acc: 0.9863 - val_loss: 0.0317 - val_acc: 0.9910\n",
      "Epoch 168/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0448 - acc: 0.9866 - val_loss: 0.0320 - val_acc: 0.9910\n",
      "Epoch 169/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0461 - acc: 0.9860 - val_loss: 0.0346 - val_acc: 0.9912\n",
      "Epoch 170/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0461 - acc: 0.9860 - val_loss: 0.0310 - val_acc: 0.9912\n",
      "Epoch 171/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0466 - acc: 0.9866 - val_loss: 0.0327 - val_acc: 0.9910\n",
      "Epoch 172/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0463 - acc: 0.9857 - val_loss: 0.0333 - val_acc: 0.9914\n",
      "Epoch 173/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0427 - acc: 0.9871 - val_loss: 0.0341 - val_acc: 0.9902\n",
      "Epoch 174/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0435 - acc: 0.9870 - val_loss: 0.0318 - val_acc: 0.9915\n",
      "Epoch 175/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0442 - acc: 0.9873 - val_loss: 0.0312 - val_acc: 0.9914\n",
      "Epoch 176/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0448 - acc: 0.9867 - val_loss: 0.0311 - val_acc: 0.9914\n",
      "Epoch 177/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0434 - acc: 0.9870 - val_loss: 0.0302 - val_acc: 0.9915\n",
      "Epoch 178/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0439 - acc: 0.9868 - val_loss: 0.0317 - val_acc: 0.9914\n",
      "Epoch 179/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0407 - acc: 0.9876 - val_loss: 0.0340 - val_acc: 0.9910\n",
      "Epoch 180/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0427 - acc: 0.9869 - val_loss: 0.0307 - val_acc: 0.9908\n",
      "Epoch 181/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0405 - acc: 0.9879 - val_loss: 0.0323 - val_acc: 0.9910\n",
      "Epoch 182/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0432 - acc: 0.9870 - val_loss: 0.0327 - val_acc: 0.9907\n",
      "Epoch 183/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0440 - acc: 0.9870 - val_loss: 0.0332 - val_acc: 0.9910\n",
      "Epoch 184/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0410 - acc: 0.9873 - val_loss: 0.0320 - val_acc: 0.9915\n",
      "Epoch 185/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0414 - acc: 0.9875 - val_loss: 0.0318 - val_acc: 0.9917\n",
      "Epoch 186/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0439 - acc: 0.9868 - val_loss: 0.0325 - val_acc: 0.9905\n",
      "Epoch 187/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0424 - acc: 0.9867 - val_loss: 0.0307 - val_acc: 0.9912\n",
      "Epoch 188/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0422 - acc: 0.9875 - val_loss: 0.0358 - val_acc: 0.9912\n",
      "Epoch 189/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0403 - acc: 0.9879 - val_loss: 0.0296 - val_acc: 0.9915\n",
      "Epoch 190/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0418 - acc: 0.9875 - val_loss: 0.0309 - val_acc: 0.9918\n",
      "Epoch 191/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0431 - acc: 0.9863 - val_loss: 0.0314 - val_acc: 0.9912\n",
      "Epoch 192/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0415 - acc: 0.9879 - val_loss: 0.0325 - val_acc: 0.9907\n",
      "Epoch 193/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0417 - acc: 0.9878 - val_loss: 0.0326 - val_acc: 0.9913\n",
      "Epoch 194/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0420 - acc: 0.9883 - val_loss: 0.0307 - val_acc: 0.9907\n",
      "Epoch 195/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0404 - acc: 0.9871 - val_loss: 0.0315 - val_acc: 0.9917\n",
      "Epoch 196/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0423 - acc: 0.9874 - val_loss: 0.0308 - val_acc: 0.9913\n",
      "Epoch 197/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0390 - acc: 0.9876 - val_loss: 0.0314 - val_acc: 0.9910\n",
      "Epoch 198/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0428 - acc: 0.9872 - val_loss: 0.0310 - val_acc: 0.9915\n",
      "Epoch 199/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0396 - acc: 0.9874 - val_loss: 0.0325 - val_acc: 0.9914\n",
      "Epoch 200/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0401 - acc: 0.9879 - val_loss: 0.0319 - val_acc: 0.9915\n",
      "Epoch 201/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0403 - acc: 0.9879 - val_loss: 0.0298 - val_acc: 0.9919\n",
      "Epoch 202/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0422 - acc: 0.9878 - val_loss: 0.0298 - val_acc: 0.9917\n",
      "Epoch 203/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0402 - acc: 0.9879 - val_loss: 0.0303 - val_acc: 0.9918\n",
      "Epoch 204/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0392 - acc: 0.9880 - val_loss: 0.0307 - val_acc: 0.9914\n",
      "Epoch 205/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0394 - acc: 0.9881 - val_loss: 0.0308 - val_acc: 0.9914\n",
      "Epoch 206/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0410 - acc: 0.9878 - val_loss: 0.0339 - val_acc: 0.9907\n",
      "Epoch 207/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0387 - acc: 0.9882 - val_loss: 0.0318 - val_acc: 0.9913\n",
      "Epoch 208/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0408 - acc: 0.9873 - val_loss: 0.0337 - val_acc: 0.9911\n",
      "Epoch 209/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0408 - acc: 0.9878 - val_loss: 0.0309 - val_acc: 0.9917\n",
      "Epoch 210/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0386 - acc: 0.9888 - val_loss: 0.0316 - val_acc: 0.9912\n",
      "Epoch 211/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0394 - acc: 0.9883 - val_loss: 0.0310 - val_acc: 0.9917\n",
      "Epoch 212/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0420 - acc: 0.9879 - val_loss: 0.0333 - val_acc: 0.9911\n",
      "Epoch 213/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0383 - acc: 0.9885 - val_loss: 0.0346 - val_acc: 0.9917\n",
      "Epoch 214/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0384 - acc: 0.9891 - val_loss: 0.0361 - val_acc: 0.9898\n",
      "Epoch 215/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0371 - acc: 0.9885 - val_loss: 0.0301 - val_acc: 0.9913\n",
      "Epoch 216/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0389 - acc: 0.9882 - val_loss: 0.0324 - val_acc: 0.9906\n",
      "Epoch 217/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0396 - acc: 0.9885 - val_loss: 0.0295 - val_acc: 0.9918\n",
      "Epoch 218/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0376 - acc: 0.9882 - val_loss: 0.0292 - val_acc: 0.9919\n",
      "Epoch 219/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0382 - acc: 0.9884 - val_loss: 0.0315 - val_acc: 0.9913\n",
      "Epoch 220/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0380 - acc: 0.9887 - val_loss: 0.0304 - val_acc: 0.9917\n",
      "Epoch 221/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0395 - acc: 0.9875 - val_loss: 0.0291 - val_acc: 0.9926\n",
      "Epoch 222/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0348 - acc: 0.9892 - val_loss: 0.0298 - val_acc: 0.9917\n",
      "Epoch 223/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0385 - acc: 0.9890 - val_loss: 0.0289 - val_acc: 0.9914\n",
      "Epoch 224/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0365 - acc: 0.9893 - val_loss: 0.0306 - val_acc: 0.9915\n",
      "Epoch 225/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0375 - acc: 0.9885 - val_loss: 0.0308 - val_acc: 0.9918\n",
      "Epoch 226/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0383 - acc: 0.9884 - val_loss: 0.0333 - val_acc: 0.9907\n",
      "Epoch 227/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0357 - acc: 0.9891 - val_loss: 0.0310 - val_acc: 0.9913\n",
      "Epoch 228/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0349 - acc: 0.9892 - val_loss: 0.0315 - val_acc: 0.9915\n",
      "Epoch 229/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0373 - acc: 0.9885 - val_loss: 0.0298 - val_acc: 0.9921\n",
      "Epoch 230/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0366 - acc: 0.9892 - val_loss: 0.0300 - val_acc: 0.9915\n",
      "Epoch 231/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0354 - acc: 0.9896 - val_loss: 0.0314 - val_acc: 0.9923\n",
      "Epoch 232/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0342 - acc: 0.9895 - val_loss: 0.0312 - val_acc: 0.9921\n",
      "Epoch 233/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0339 - acc: 0.9895 - val_loss: 0.0316 - val_acc: 0.9913\n",
      "Epoch 234/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0356 - acc: 0.9897 - val_loss: 0.0303 - val_acc: 0.9920\n",
      "Epoch 235/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0333 - acc: 0.9900 - val_loss: 0.0315 - val_acc: 0.9915\n",
      "Epoch 236/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0370 - acc: 0.9898 - val_loss: 0.0302 - val_acc: 0.9918\n",
      "Epoch 237/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0341 - acc: 0.9899 - val_loss: 0.0326 - val_acc: 0.9913\n",
      "Epoch 238/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0354 - acc: 0.9892 - val_loss: 0.0320 - val_acc: 0.9914\n",
      "Epoch 239/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0339 - acc: 0.9898 - val_loss: 0.0307 - val_acc: 0.9924\n",
      "Epoch 240/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0357 - acc: 0.9888 - val_loss: 0.0310 - val_acc: 0.9921\n",
      "Epoch 241/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0337 - acc: 0.9900 - val_loss: 0.0292 - val_acc: 0.9921\n",
      "Epoch 242/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0376 - acc: 0.9891 - val_loss: 0.0296 - val_acc: 0.9924\n",
      "Epoch 243/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0349 - acc: 0.9892 - val_loss: 0.0313 - val_acc: 0.9913\n",
      "Epoch 244/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0336 - acc: 0.9899 - val_loss: 0.0303 - val_acc: 0.9920\n",
      "Epoch 245/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0348 - acc: 0.9898 - val_loss: 0.0306 - val_acc: 0.9917\n",
      "Epoch 246/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0346 - acc: 0.9894 - val_loss: 0.0329 - val_acc: 0.9917\n",
      "Epoch 247/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0341 - acc: 0.9895 - val_loss: 0.0296 - val_acc: 0.9914\n",
      "Epoch 248/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0343 - acc: 0.9888 - val_loss: 0.0308 - val_acc: 0.9918\n",
      "Epoch 249/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0333 - acc: 0.9895 - val_loss: 0.0334 - val_acc: 0.9913\n",
      "Epoch 250/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0325 - acc: 0.9903 - val_loss: 0.0307 - val_acc: 0.9919\n",
      "Epoch 251/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0331 - acc: 0.9893 - val_loss: 0.0315 - val_acc: 0.9923\n",
      "Epoch 252/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0342 - acc: 0.9903 - val_loss: 0.0305 - val_acc: 0.9919\n",
      "Epoch 253/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0339 - acc: 0.9905 - val_loss: 0.0326 - val_acc: 0.9912\n",
      "Epoch 254/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0327 - acc: 0.9897 - val_loss: 0.0312 - val_acc: 0.9918\n",
      "Epoch 255/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0337 - acc: 0.9904 - val_loss: 0.0309 - val_acc: 0.9917\n",
      "Epoch 256/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0324 - acc: 0.9904 - val_loss: 0.0320 - val_acc: 0.9920\n",
      "Epoch 257/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0332 - acc: 0.9910 - val_loss: 0.0319 - val_acc: 0.9917\n",
      "Epoch 258/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0330 - acc: 0.9896 - val_loss: 0.0323 - val_acc: 0.9914\n",
      "Epoch 259/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0315 - acc: 0.9899 - val_loss: 0.0307 - val_acc: 0.9920\n",
      "Epoch 260/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0321 - acc: 0.9899 - val_loss: 0.0302 - val_acc: 0.9924\n",
      "Epoch 261/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0316 - acc: 0.9907 - val_loss: 0.0308 - val_acc: 0.9920\n",
      "Epoch 262/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0351 - acc: 0.9888 - val_loss: 0.0303 - val_acc: 0.9915\n",
      "Epoch 263/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0329 - acc: 0.9901 - val_loss: 0.0332 - val_acc: 0.9913\n",
      "Epoch 264/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0321 - acc: 0.9901 - val_loss: 0.0307 - val_acc: 0.9925\n",
      "Epoch 265/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0338 - acc: 0.9901 - val_loss: 0.0297 - val_acc: 0.9921\n",
      "Epoch 266/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0328 - acc: 0.9899 - val_loss: 0.0321 - val_acc: 0.9912\n",
      "Epoch 267/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0308 - acc: 0.9910 - val_loss: 0.0320 - val_acc: 0.9920\n",
      "Epoch 268/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0347 - acc: 0.9889 - val_loss: 0.0319 - val_acc: 0.9921\n",
      "Epoch 269/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0328 - acc: 0.9906 - val_loss: 0.0284 - val_acc: 0.9915\n",
      "Epoch 270/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0313 - acc: 0.9900 - val_loss: 0.0303 - val_acc: 0.9919\n",
      "Epoch 271/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0347 - acc: 0.9896 - val_loss: 0.0305 - val_acc: 0.9920\n",
      "Epoch 272/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0296 - acc: 0.9906 - val_loss: 0.0345 - val_acc: 0.9913\n",
      "Epoch 273/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0303 - acc: 0.9903 - val_loss: 0.0347 - val_acc: 0.9915\n",
      "Epoch 274/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0317 - acc: 0.9904 - val_loss: 0.0286 - val_acc: 0.9919\n",
      "Epoch 275/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0329 - acc: 0.9899 - val_loss: 0.0354 - val_acc: 0.9911\n",
      "Epoch 276/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0299 - acc: 0.9910 - val_loss: 0.0295 - val_acc: 0.9926\n",
      "Epoch 277/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0311 - acc: 0.9905 - val_loss: 0.0315 - val_acc: 0.9924\n",
      "Epoch 278/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0311 - acc: 0.9910 - val_loss: 0.0299 - val_acc: 0.9919\n",
      "Epoch 279/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0289 - acc: 0.9907 - val_loss: 0.0296 - val_acc: 0.9925\n",
      "Epoch 280/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0325 - acc: 0.9902 - val_loss: 0.0302 - val_acc: 0.9921\n",
      "Epoch 281/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0305 - acc: 0.9914 - val_loss: 0.0283 - val_acc: 0.9924\n",
      "Epoch 282/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0292 - acc: 0.9907 - val_loss: 0.0311 - val_acc: 0.9918\n",
      "Epoch 283/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0305 - acc: 0.9906 - val_loss: 0.0328 - val_acc: 0.9923\n",
      "Epoch 284/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0309 - acc: 0.9907 - val_loss: 0.0332 - val_acc: 0.9921\n",
      "Epoch 285/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0279 - acc: 0.9916 - val_loss: 0.0295 - val_acc: 0.9926\n",
      "Epoch 286/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0311 - acc: 0.9907 - val_loss: 0.0291 - val_acc: 0.9920\n",
      "Epoch 287/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0295 - acc: 0.9911 - val_loss: 0.0314 - val_acc: 0.9926\n",
      "Epoch 288/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0315 - acc: 0.9904 - val_loss: 0.0299 - val_acc: 0.9920\n",
      "Epoch 289/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0308 - acc: 0.9904 - val_loss: 0.0320 - val_acc: 0.9918\n",
      "Epoch 290/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0308 - acc: 0.9897 - val_loss: 0.0307 - val_acc: 0.9923\n",
      "Epoch 291/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0296 - acc: 0.9907 - val_loss: 0.0322 - val_acc: 0.9919\n",
      "Epoch 292/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0293 - acc: 0.9913 - val_loss: 0.0314 - val_acc: 0.9921\n",
      "Epoch 293/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0308 - acc: 0.9904 - val_loss: 0.0307 - val_acc: 0.9918\n",
      "Epoch 294/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0320 - acc: 0.9901 - val_loss: 0.0282 - val_acc: 0.9919\n",
      "Epoch 295/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0302 - acc: 0.9901 - val_loss: 0.0316 - val_acc: 0.9920\n",
      "Epoch 296/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0299 - acc: 0.9905 - val_loss: 0.0295 - val_acc: 0.9920\n",
      "Epoch 297/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0298 - acc: 0.9912 - val_loss: 0.0315 - val_acc: 0.9915\n",
      "Epoch 298/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0306 - acc: 0.9902 - val_loss: 0.0272 - val_acc: 0.9929\n",
      "Epoch 299/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0288 - acc: 0.9910 - val_loss: 0.0298 - val_acc: 0.9918\n",
      "Epoch 300/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0303 - acc: 0.9906 - val_loss: 0.0316 - val_acc: 0.9914\n",
      "Epoch 301/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0300 - acc: 0.9913 - val_loss: 0.0282 - val_acc: 0.9927\n",
      "Epoch 302/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0302 - acc: 0.9908 - val_loss: 0.0298 - val_acc: 0.9929\n",
      "Epoch 303/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0284 - acc: 0.9912 - val_loss: 0.0321 - val_acc: 0.9918\n",
      "Epoch 304/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0298 - acc: 0.9910 - val_loss: 0.0302 - val_acc: 0.9924\n",
      "Epoch 305/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0294 - acc: 0.9905 - val_loss: 0.0281 - val_acc: 0.9929\n",
      "Epoch 306/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0282 - acc: 0.9916 - val_loss: 0.0333 - val_acc: 0.9918\n",
      "Epoch 307/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0297 - acc: 0.9906 - val_loss: 0.0295 - val_acc: 0.9932\n",
      "Epoch 308/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0287 - acc: 0.9916 - val_loss: 0.0260 - val_acc: 0.9926\n",
      "Epoch 309/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0289 - acc: 0.9912 - val_loss: 0.0290 - val_acc: 0.9925\n",
      "Epoch 310/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0290 - acc: 0.9907 - val_loss: 0.0319 - val_acc: 0.9920\n",
      "Epoch 311/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0306 - acc: 0.9908 - val_loss: 0.0327 - val_acc: 0.9919\n",
      "Epoch 312/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0285 - acc: 0.9917 - val_loss: 0.0335 - val_acc: 0.9921\n",
      "Epoch 313/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0275 - acc: 0.9918 - val_loss: 0.0334 - val_acc: 0.9913\n",
      "Epoch 314/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0272 - acc: 0.9917 - val_loss: 0.0294 - val_acc: 0.9924\n",
      "Epoch 315/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0313 - acc: 0.9909 - val_loss: 0.0285 - val_acc: 0.9920\n",
      "Epoch 316/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0283 - acc: 0.9914 - val_loss: 0.0286 - val_acc: 0.9929\n",
      "Epoch 317/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0279 - acc: 0.9914 - val_loss: 0.0313 - val_acc: 0.9927\n",
      "Epoch 318/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0283 - acc: 0.9910 - val_loss: 0.0294 - val_acc: 0.9923\n",
      "Epoch 319/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0266 - acc: 0.9915 - val_loss: 0.0291 - val_acc: 0.9925\n",
      "Epoch 320/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0267 - acc: 0.9918 - val_loss: 0.0332 - val_acc: 0.9918\n",
      "Epoch 321/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0287 - acc: 0.9914 - val_loss: 0.0304 - val_acc: 0.9924\n",
      "Epoch 322/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0281 - acc: 0.9912 - val_loss: 0.0309 - val_acc: 0.9918\n",
      "Epoch 323/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0264 - acc: 0.9920 - val_loss: 0.0309 - val_acc: 0.9919\n",
      "Epoch 324/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0274 - acc: 0.9919 - val_loss: 0.0287 - val_acc: 0.9925\n",
      "Epoch 325/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0303 - acc: 0.9902 - val_loss: 0.0288 - val_acc: 0.9921\n",
      "Epoch 326/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0268 - acc: 0.9916 - val_loss: 0.0323 - val_acc: 0.9913\n",
      "Epoch 327/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0265 - acc: 0.9916 - val_loss: 0.0291 - val_acc: 0.9927\n",
      "Epoch 328/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0283 - acc: 0.9914 - val_loss: 0.0315 - val_acc: 0.9911\n",
      "Epoch 329/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0282 - acc: 0.9913 - val_loss: 0.0296 - val_acc: 0.9919\n",
      "Epoch 330/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0274 - acc: 0.9915 - val_loss: 0.0304 - val_acc: 0.9925\n",
      "Epoch 331/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0269 - acc: 0.9916 - val_loss: 0.0334 - val_acc: 0.9918\n",
      "Epoch 332/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0278 - acc: 0.9916 - val_loss: 0.0279 - val_acc: 0.9920\n",
      "Epoch 333/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0272 - acc: 0.9920 - val_loss: 0.0278 - val_acc: 0.9924\n",
      "Epoch 334/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0270 - acc: 0.9920 - val_loss: 0.0313 - val_acc: 0.9920\n",
      "Epoch 335/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0259 - acc: 0.9921 - val_loss: 0.0311 - val_acc: 0.9915\n",
      "Epoch 336/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0287 - acc: 0.9905 - val_loss: 0.0284 - val_acc: 0.9924\n",
      "Epoch 337/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0269 - acc: 0.9915 - val_loss: 0.0302 - val_acc: 0.9919\n",
      "Epoch 338/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0261 - acc: 0.9918 - val_loss: 0.0292 - val_acc: 0.9927\n",
      "Epoch 339/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0263 - acc: 0.9920 - val_loss: 0.0315 - val_acc: 0.9926\n",
      "Epoch 340/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0268 - acc: 0.9919 - val_loss: 0.0338 - val_acc: 0.9914\n",
      "Epoch 341/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0254 - acc: 0.9920 - val_loss: 0.0295 - val_acc: 0.9926\n",
      "Epoch 342/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0237 - acc: 0.9924 - val_loss: 0.0294 - val_acc: 0.9927\n",
      "Epoch 343/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0268 - acc: 0.9921 - val_loss: 0.0277 - val_acc: 0.9921\n",
      "Epoch 344/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0253 - acc: 0.9920 - val_loss: 0.0315 - val_acc: 0.9923\n",
      "Epoch 345/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0277 - acc: 0.9911 - val_loss: 0.0280 - val_acc: 0.9925\n",
      "Epoch 346/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0265 - acc: 0.9915 - val_loss: 0.0292 - val_acc: 0.9925\n",
      "Epoch 347/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0270 - acc: 0.9918 - val_loss: 0.0301 - val_acc: 0.9920\n",
      "Epoch 348/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0268 - acc: 0.9915 - val_loss: 0.0296 - val_acc: 0.9929\n",
      "Epoch 349/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0260 - acc: 0.9924 - val_loss: 0.0317 - val_acc: 0.9919\n",
      "Epoch 350/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0278 - acc: 0.9913 - val_loss: 0.0287 - val_acc: 0.9925\n",
      "Epoch 351/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0238 - acc: 0.9926 - val_loss: 0.0316 - val_acc: 0.9923\n",
      "Epoch 352/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0247 - acc: 0.9924 - val_loss: 0.0312 - val_acc: 0.9919\n",
      "Epoch 353/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0261 - acc: 0.9921 - val_loss: 0.0297 - val_acc: 0.9923\n",
      "Epoch 354/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0251 - acc: 0.9927 - val_loss: 0.0309 - val_acc: 0.9926\n",
      "Epoch 355/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0274 - acc: 0.9911 - val_loss: 0.0299 - val_acc: 0.9927\n",
      "Epoch 356/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0247 - acc: 0.9925 - val_loss: 0.0309 - val_acc: 0.9927\n",
      "Epoch 357/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0231 - acc: 0.9924 - val_loss: 0.0290 - val_acc: 0.9927\n",
      "Epoch 358/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0265 - acc: 0.9917 - val_loss: 0.0294 - val_acc: 0.9927\n",
      "Epoch 359/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0252 - acc: 0.9919 - val_loss: 0.0275 - val_acc: 0.9931\n",
      "Epoch 360/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0265 - acc: 0.9919 - val_loss: 0.0310 - val_acc: 0.9923\n",
      "Epoch 361/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0243 - acc: 0.9927 - val_loss: 0.0263 - val_acc: 0.9936\n",
      "Epoch 362/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0256 - acc: 0.9919 - val_loss: 0.0318 - val_acc: 0.9915\n",
      "Epoch 363/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0246 - acc: 0.9929 - val_loss: 0.0309 - val_acc: 0.9921\n",
      "Epoch 364/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0263 - acc: 0.9921 - val_loss: 0.0294 - val_acc: 0.9925\n",
      "Epoch 365/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0267 - acc: 0.9918 - val_loss: 0.0292 - val_acc: 0.9921\n",
      "Epoch 366/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0251 - acc: 0.9919 - val_loss: 0.0345 - val_acc: 0.9919\n",
      "Epoch 367/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0266 - acc: 0.9921 - val_loss: 0.0282 - val_acc: 0.9936\n",
      "Epoch 368/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0234 - acc: 0.9923 - val_loss: 0.0278 - val_acc: 0.9930\n",
      "Epoch 369/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0249 - acc: 0.9926 - val_loss: 0.0351 - val_acc: 0.9917\n",
      "Epoch 370/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0244 - acc: 0.9933 - val_loss: 0.0303 - val_acc: 0.9923\n",
      "Epoch 371/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0252 - acc: 0.9922 - val_loss: 0.0330 - val_acc: 0.9920\n",
      "Epoch 372/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0240 - acc: 0.9930 - val_loss: 0.0285 - val_acc: 0.9925\n",
      "Epoch 373/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0239 - acc: 0.9924 - val_loss: 0.0325 - val_acc: 0.9925\n",
      "Epoch 374/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0264 - acc: 0.9921 - val_loss: 0.0324 - val_acc: 0.9919\n",
      "Epoch 375/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0238 - acc: 0.9924 - val_loss: 0.0325 - val_acc: 0.9926\n",
      "Epoch 376/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0250 - acc: 0.9924 - val_loss: 0.0318 - val_acc: 0.9927\n",
      "Epoch 377/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0261 - acc: 0.9920 - val_loss: 0.0347 - val_acc: 0.9921\n",
      "Epoch 378/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0236 - acc: 0.9928 - val_loss: 0.0290 - val_acc: 0.9932\n",
      "Epoch 379/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0233 - acc: 0.9931 - val_loss: 0.0323 - val_acc: 0.9924\n",
      "Epoch 380/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0242 - acc: 0.9928 - val_loss: 0.0283 - val_acc: 0.9919\n",
      "Epoch 381/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0241 - acc: 0.9922 - val_loss: 0.0288 - val_acc: 0.9925\n",
      "Epoch 382/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0229 - acc: 0.9928 - val_loss: 0.0321 - val_acc: 0.9923\n",
      "Epoch 383/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0262 - acc: 0.9917 - val_loss: 0.0286 - val_acc: 0.9924\n",
      "Epoch 384/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0250 - acc: 0.9920 - val_loss: 0.0281 - val_acc: 0.9933\n",
      "Epoch 385/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0238 - acc: 0.9922 - val_loss: 0.0288 - val_acc: 0.9927\n",
      "Epoch 386/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0247 - acc: 0.9921 - val_loss: 0.0325 - val_acc: 0.9910\n",
      "Epoch 387/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0235 - acc: 0.9926 - val_loss: 0.0264 - val_acc: 0.9923\n",
      "Epoch 388/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0237 - acc: 0.9931 - val_loss: 0.0303 - val_acc: 0.9923\n",
      "Epoch 389/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0241 - acc: 0.9924 - val_loss: 0.0296 - val_acc: 0.9917\n",
      "Epoch 390/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0234 - acc: 0.9927 - val_loss: 0.0311 - val_acc: 0.9925\n",
      "Epoch 391/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0246 - acc: 0.9923 - val_loss: 0.0335 - val_acc: 0.9919\n",
      "Epoch 392/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0238 - acc: 0.9927 - val_loss: 0.0279 - val_acc: 0.9932\n",
      "Epoch 393/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0240 - acc: 0.9923 - val_loss: 0.0333 - val_acc: 0.9925\n",
      "Epoch 394/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0246 - acc: 0.9925 - val_loss: 0.0313 - val_acc: 0.9914\n",
      "Epoch 395/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0248 - acc: 0.9918 - val_loss: 0.0292 - val_acc: 0.9929\n",
      "Epoch 396/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0250 - acc: 0.9922 - val_loss: 0.0283 - val_acc: 0.9921\n",
      "Epoch 397/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0215 - acc: 0.9930 - val_loss: 0.0261 - val_acc: 0.9927\n",
      "Epoch 398/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0229 - acc: 0.9930 - val_loss: 0.0270 - val_acc: 0.9927\n",
      "Epoch 399/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0239 - acc: 0.9924 - val_loss: 0.0290 - val_acc: 0.9924\n",
      "Epoch 400/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0226 - acc: 0.9929 - val_loss: 0.0309 - val_acc: 0.9925\n",
      "Epoch 401/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0231 - acc: 0.9933 - val_loss: 0.0299 - val_acc: 0.9921\n",
      "Epoch 402/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0233 - acc: 0.9932 - val_loss: 0.0299 - val_acc: 0.9927\n",
      "Epoch 403/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0232 - acc: 0.9924 - val_loss: 0.0298 - val_acc: 0.9925\n",
      "Epoch 404/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0239 - acc: 0.9926 - val_loss: 0.0266 - val_acc: 0.9925\n",
      "Epoch 405/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0234 - acc: 0.9926 - val_loss: 0.0285 - val_acc: 0.9925\n",
      "Epoch 406/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0242 - acc: 0.9922 - val_loss: 0.0353 - val_acc: 0.9918\n",
      "Epoch 407/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0206 - acc: 0.9933 - val_loss: 0.0295 - val_acc: 0.9924\n",
      "Epoch 408/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0249 - acc: 0.9918 - val_loss: 0.0263 - val_acc: 0.9927\n",
      "Epoch 409/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0213 - acc: 0.9938 - val_loss: 0.0296 - val_acc: 0.9920\n",
      "Epoch 410/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0225 - acc: 0.9926 - val_loss: 0.0317 - val_acc: 0.9923\n",
      "Epoch 411/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0219 - acc: 0.9935 - val_loss: 0.0292 - val_acc: 0.9930\n",
      "Epoch 412/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0252 - acc: 0.9926 - val_loss: 0.0284 - val_acc: 0.9925\n",
      "Epoch 413/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0216 - acc: 0.9930 - val_loss: 0.0285 - val_acc: 0.9926\n",
      "Epoch 414/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0232 - acc: 0.9926 - val_loss: 0.0303 - val_acc: 0.9929\n",
      "Epoch 415/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0234 - acc: 0.9928 - val_loss: 0.0269 - val_acc: 0.9925\n",
      "Epoch 416/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0217 - acc: 0.9932 - val_loss: 0.0320 - val_acc: 0.9930\n",
      "Epoch 417/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0200 - acc: 0.9940 - val_loss: 0.0278 - val_acc: 0.9924\n",
      "Epoch 418/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0210 - acc: 0.9938 - val_loss: 0.0282 - val_acc: 0.9927\n",
      "Epoch 419/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0215 - acc: 0.9928 - val_loss: 0.0286 - val_acc: 0.9924\n",
      "Epoch 420/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0225 - acc: 0.9929 - val_loss: 0.0291 - val_acc: 0.9921\n",
      "Epoch 421/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0225 - acc: 0.9933 - val_loss: 0.0289 - val_acc: 0.9918\n",
      "Epoch 422/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0221 - acc: 0.9934 - val_loss: 0.0279 - val_acc: 0.9927\n",
      "Epoch 423/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0216 - acc: 0.9933 - val_loss: 0.0292 - val_acc: 0.9929\n",
      "Epoch 424/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0244 - acc: 0.9926 - val_loss: 0.0276 - val_acc: 0.9925\n",
      "Epoch 425/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0208 - acc: 0.9931 - val_loss: 0.0258 - val_acc: 0.9924\n",
      "Epoch 426/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0232 - acc: 0.9927 - val_loss: 0.0332 - val_acc: 0.9924\n",
      "Epoch 427/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0204 - acc: 0.9937 - val_loss: 0.0280 - val_acc: 0.9927\n",
      "Epoch 428/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0248 - acc: 0.9932 - val_loss: 0.0259 - val_acc: 0.9927\n",
      "Epoch 429/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0217 - acc: 0.9936 - val_loss: 0.0326 - val_acc: 0.9917\n",
      "Epoch 430/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0238 - acc: 0.9924 - val_loss: 0.0308 - val_acc: 0.9923\n",
      "Epoch 431/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0224 - acc: 0.9928 - val_loss: 0.0276 - val_acc: 0.9929\n",
      "Epoch 432/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0213 - acc: 0.9937 - val_loss: 0.0322 - val_acc: 0.9920\n",
      "Epoch 433/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0223 - acc: 0.9927 - val_loss: 0.0273 - val_acc: 0.9926\n",
      "Epoch 434/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0238 - acc: 0.9928 - val_loss: 0.0292 - val_acc: 0.9924\n",
      "Epoch 435/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0206 - acc: 0.9936 - val_loss: 0.0275 - val_acc: 0.9932\n",
      "Epoch 436/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0222 - acc: 0.9932 - val_loss: 0.0296 - val_acc: 0.9923\n",
      "Epoch 437/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0206 - acc: 0.9937 - val_loss: 0.0256 - val_acc: 0.9926\n",
      "Epoch 438/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0211 - acc: 0.9929 - val_loss: 0.0287 - val_acc: 0.9927\n",
      "Epoch 439/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0215 - acc: 0.9930 - val_loss: 0.0304 - val_acc: 0.9932\n",
      "Epoch 440/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0203 - acc: 0.9938 - val_loss: 0.0307 - val_acc: 0.9927\n",
      "Epoch 441/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0229 - acc: 0.9931 - val_loss: 0.0302 - val_acc: 0.9924\n",
      "Epoch 442/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0216 - acc: 0.9934 - val_loss: 0.0290 - val_acc: 0.9929\n",
      "Epoch 443/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0218 - acc: 0.9929 - val_loss: 0.0283 - val_acc: 0.9929\n",
      "Epoch 444/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0194 - acc: 0.9936 - val_loss: 0.0275 - val_acc: 0.9929\n",
      "Epoch 445/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0216 - acc: 0.9928 - val_loss: 0.0304 - val_acc: 0.9925\n",
      "Epoch 446/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0209 - acc: 0.9933 - val_loss: 0.0305 - val_acc: 0.9926\n",
      "Epoch 447/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0207 - acc: 0.9935 - val_loss: 0.0309 - val_acc: 0.9930\n",
      "Epoch 448/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0208 - acc: 0.9935 - val_loss: 0.0293 - val_acc: 0.9921\n",
      "Epoch 449/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0209 - acc: 0.9935 - val_loss: 0.0291 - val_acc: 0.9927\n",
      "Epoch 450/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0200 - acc: 0.9937 - val_loss: 0.0291 - val_acc: 0.9930\n",
      "Epoch 451/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0211 - acc: 0.9929 - val_loss: 0.0286 - val_acc: 0.9925\n",
      "Epoch 452/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0224 - acc: 0.9933 - val_loss: 0.0266 - val_acc: 0.9924\n",
      "Epoch 453/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0209 - acc: 0.9933 - val_loss: 0.0303 - val_acc: 0.9919\n",
      "Epoch 454/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0205 - acc: 0.9936 - val_loss: 0.0338 - val_acc: 0.9920\n",
      "Epoch 455/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0208 - acc: 0.9936 - val_loss: 0.0300 - val_acc: 0.9924\n",
      "Epoch 456/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0214 - acc: 0.9932 - val_loss: 0.0340 - val_acc: 0.9918\n",
      "Epoch 457/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0207 - acc: 0.9932 - val_loss: 0.0318 - val_acc: 0.9926\n",
      "Epoch 458/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0210 - acc: 0.9931 - val_loss: 0.0304 - val_acc: 0.9923\n",
      "Epoch 459/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0212 - acc: 0.9940 - val_loss: 0.0329 - val_acc: 0.9919\n",
      "Epoch 460/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0212 - acc: 0.9931 - val_loss: 0.0323 - val_acc: 0.9918\n",
      "Epoch 461/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0199 - acc: 0.9935 - val_loss: 0.0360 - val_acc: 0.9921\n",
      "Epoch 462/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0195 - acc: 0.9938 - val_loss: 0.0310 - val_acc: 0.9927\n",
      "Epoch 463/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0210 - acc: 0.9937 - val_loss: 0.0305 - val_acc: 0.9924\n",
      "Epoch 464/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0224 - acc: 0.9926 - val_loss: 0.0306 - val_acc: 0.9927\n",
      "Epoch 465/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0214 - acc: 0.9937 - val_loss: 0.0313 - val_acc: 0.9920\n",
      "Epoch 466/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0212 - acc: 0.9932 - val_loss: 0.0290 - val_acc: 0.9930\n",
      "Epoch 467/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0213 - acc: 0.9928 - val_loss: 0.0272 - val_acc: 0.9924\n",
      "Epoch 468/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0226 - acc: 0.9924 - val_loss: 0.0282 - val_acc: 0.9925\n",
      "Epoch 469/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0212 - acc: 0.9930 - val_loss: 0.0288 - val_acc: 0.9925\n",
      "Epoch 470/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0202 - acc: 0.9935 - val_loss: 0.0271 - val_acc: 0.9935\n",
      "Epoch 471/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0212 - acc: 0.9929 - val_loss: 0.0308 - val_acc: 0.9924\n",
      "Epoch 472/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0195 - acc: 0.9939 - val_loss: 0.0311 - val_acc: 0.9926\n",
      "Epoch 473/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0204 - acc: 0.9933 - val_loss: 0.0282 - val_acc: 0.9924\n",
      "Epoch 474/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0212 - acc: 0.9930 - val_loss: 0.0268 - val_acc: 0.9929\n",
      "Epoch 475/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0224 - acc: 0.9930 - val_loss: 0.0295 - val_acc: 0.9925\n",
      "Epoch 476/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0205 - acc: 0.9937 - val_loss: 0.0295 - val_acc: 0.9929\n",
      "Epoch 477/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0195 - acc: 0.9937 - val_loss: 0.0294 - val_acc: 0.9929\n",
      "Epoch 478/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0196 - acc: 0.9934 - val_loss: 0.0290 - val_acc: 0.9929\n",
      "Epoch 479/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0185 - acc: 0.9946 - val_loss: 0.0294 - val_acc: 0.9933\n",
      "Epoch 480/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0198 - acc: 0.9942 - val_loss: 0.0263 - val_acc: 0.9925\n",
      "Epoch 481/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0199 - acc: 0.9936 - val_loss: 0.0288 - val_acc: 0.9925\n",
      "Epoch 482/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0189 - acc: 0.9940 - val_loss: 0.0292 - val_acc: 0.9927\n",
      "Epoch 483/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0195 - acc: 0.9938 - val_loss: 0.0284 - val_acc: 0.9930\n",
      "Epoch 484/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0192 - acc: 0.9935 - val_loss: 0.0285 - val_acc: 0.9930\n",
      "Epoch 485/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0210 - acc: 0.9934 - val_loss: 0.0255 - val_acc: 0.9926\n",
      "Epoch 486/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0199 - acc: 0.9937 - val_loss: 0.0269 - val_acc: 0.9927\n",
      "Epoch 487/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0185 - acc: 0.9939 - val_loss: 0.0268 - val_acc: 0.9929\n",
      "Epoch 488/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0199 - acc: 0.9937 - val_loss: 0.0292 - val_acc: 0.9929\n",
      "Epoch 489/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0219 - acc: 0.9932 - val_loss: 0.0313 - val_acc: 0.9924\n",
      "Epoch 490/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0203 - acc: 0.9935 - val_loss: 0.0284 - val_acc: 0.9927\n",
      "Epoch 491/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0211 - acc: 0.9936 - val_loss: 0.0291 - val_acc: 0.9925\n",
      "Epoch 492/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0191 - acc: 0.9940 - val_loss: 0.0319 - val_acc: 0.9913\n",
      "Epoch 493/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0174 - acc: 0.9939 - val_loss: 0.0310 - val_acc: 0.9931\n",
      "Epoch 494/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0187 - acc: 0.9943 - val_loss: 0.0279 - val_acc: 0.9933\n",
      "Epoch 495/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0213 - acc: 0.9935 - val_loss: 0.0271 - val_acc: 0.9926\n",
      "Epoch 496/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0188 - acc: 0.9941 - val_loss: 0.0287 - val_acc: 0.9929\n",
      "Epoch 497/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0185 - acc: 0.9940 - val_loss: 0.0254 - val_acc: 0.9933\n",
      "Epoch 498/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0187 - acc: 0.9937 - val_loss: 0.0296 - val_acc: 0.9932\n",
      "Epoch 499/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0198 - acc: 0.9939 - val_loss: 0.0307 - val_acc: 0.9930\n",
      "Epoch 500/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0205 - acc: 0.9939 - val_loss: 0.0318 - val_acc: 0.9921\n",
      "Epoch 501/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0207 - acc: 0.9936 - val_loss: 0.0306 - val_acc: 0.9924\n",
      "Epoch 502/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0204 - acc: 0.9931 - val_loss: 0.0276 - val_acc: 0.9929\n",
      "Epoch 503/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0181 - acc: 0.9946 - val_loss: 0.0307 - val_acc: 0.9926\n",
      "Epoch 504/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0176 - acc: 0.9943 - val_loss: 0.0319 - val_acc: 0.9931\n",
      "Epoch 505/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0196 - acc: 0.9937 - val_loss: 0.0282 - val_acc: 0.9927\n",
      "Epoch 506/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0176 - acc: 0.9943 - val_loss: 0.0282 - val_acc: 0.9930\n",
      "Epoch 507/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0180 - acc: 0.9941 - val_loss: 0.0302 - val_acc: 0.9926\n",
      "Epoch 508/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0184 - acc: 0.9941 - val_loss: 0.0290 - val_acc: 0.9933\n",
      "Epoch 509/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0191 - acc: 0.9938 - val_loss: 0.0291 - val_acc: 0.9932\n",
      "Epoch 510/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0172 - acc: 0.9944 - val_loss: 0.0278 - val_acc: 0.9935\n",
      "Epoch 511/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0209 - acc: 0.9938 - val_loss: 0.0268 - val_acc: 0.9932\n",
      "Epoch 512/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0168 - acc: 0.9949 - val_loss: 0.0306 - val_acc: 0.9925\n",
      "Epoch 513/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0196 - acc: 0.9937 - val_loss: 0.0278 - val_acc: 0.9932\n",
      "Epoch 514/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0181 - acc: 0.9946 - val_loss: 0.0289 - val_acc: 0.9927\n",
      "Epoch 515/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0192 - acc: 0.9942 - val_loss: 0.0267 - val_acc: 0.9923\n",
      "Epoch 516/600\n",
      "33600/33600 [==============================] - 68s 2ms/step - loss: 0.0194 - acc: 0.9937 - val_loss: 0.0268 - val_acc: 0.9929\n",
      "Epoch 517/600\n",
      "33600/33600 [==============================] - 69s 2ms/step - loss: 0.0198 - acc: 0.9935 - val_loss: 0.0285 - val_acc: 0.9925\n",
      "Epoch 518/600\n",
      "33600/33600 [==============================] - 68s 2ms/step - loss: 0.0182 - acc: 0.9940 - val_loss: 0.0330 - val_acc: 0.9926\n",
      "Epoch 519/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0189 - acc: 0.9941 - val_loss: 0.0289 - val_acc: 0.9932\n",
      "Epoch 520/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0226 - acc: 0.9929 - val_loss: 0.0279 - val_acc: 0.9933\n",
      "Epoch 521/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0194 - acc: 0.9941 - val_loss: 0.0286 - val_acc: 0.9927\n",
      "Epoch 522/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0181 - acc: 0.9944 - val_loss: 0.0250 - val_acc: 0.9930\n",
      "Epoch 523/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0187 - acc: 0.9941 - val_loss: 0.0285 - val_acc: 0.9931\n",
      "Epoch 524/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0179 - acc: 0.9943 - val_loss: 0.0303 - val_acc: 0.9930\n",
      "Epoch 525/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0205 - acc: 0.9935 - val_loss: 0.0278 - val_acc: 0.9929\n",
      "Epoch 526/600\n",
      "33600/33600 [==============================] - 67s 2ms/step - loss: 0.0174 - acc: 0.9947 - val_loss: 0.0290 - val_acc: 0.9929\n",
      "Epoch 527/600\n",
      "33600/33600 [==============================] - 71s 2ms/step - loss: 0.0161 - acc: 0.9947 - val_loss: 0.0321 - val_acc: 0.9918\n",
      "Epoch 528/600\n",
      "33600/33600 [==============================] - 66s 2ms/step - loss: 0.0186 - acc: 0.9937 - val_loss: 0.0286 - val_acc: 0.9927\n",
      "Epoch 529/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0186 - acc: 0.9937 - val_loss: 0.0270 - val_acc: 0.9930\n",
      "Epoch 530/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0174 - acc: 0.9948 - val_loss: 0.0294 - val_acc: 0.9927\n",
      "Epoch 531/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0176 - acc: 0.9941 - val_loss: 0.0306 - val_acc: 0.9925\n",
      "Epoch 532/600\n",
      "33600/33600 [==============================] - 64s 2ms/step - loss: 0.0182 - acc: 0.9945 - val_loss: 0.0266 - val_acc: 0.9935\n",
      "Epoch 533/600\n",
      "33600/33600 [==============================] - 64s 2ms/step - loss: 0.0182 - acc: 0.9941 - val_loss: 0.0272 - val_acc: 0.9930\n",
      "Epoch 534/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0167 - acc: 0.9949 - val_loss: 0.0279 - val_acc: 0.9929\n",
      "Epoch 535/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0183 - acc: 0.9945 - val_loss: 0.0318 - val_acc: 0.9919\n",
      "Epoch 536/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0193 - acc: 0.9941 - val_loss: 0.0310 - val_acc: 0.9919\n",
      "Epoch 537/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0196 - acc: 0.9939 - val_loss: 0.0276 - val_acc: 0.9930\n",
      "Epoch 538/600\n",
      "33600/33600 [==============================] - 64s 2ms/step - loss: 0.0156 - acc: 0.9952 - val_loss: 0.0306 - val_acc: 0.9919\n",
      "Epoch 539/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0188 - acc: 0.9945 - val_loss: 0.0292 - val_acc: 0.9925\n",
      "Epoch 540/600\n",
      "33600/33600 [==============================] - 64s 2ms/step - loss: 0.0180 - acc: 0.9940 - val_loss: 0.0276 - val_acc: 0.9933\n",
      "Epoch 541/600\n",
      "33600/33600 [==============================] - 64s 2ms/step - loss: 0.0188 - acc: 0.9938 - val_loss: 0.0307 - val_acc: 0.9924\n",
      "Epoch 542/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0168 - acc: 0.9946 - val_loss: 0.0270 - val_acc: 0.9932\n",
      "Epoch 543/600\n",
      "33600/33600 [==============================] - 64s 2ms/step - loss: 0.0168 - acc: 0.9950 - val_loss: 0.0347 - val_acc: 0.9924\n",
      "Epoch 544/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0178 - acc: 0.9945 - val_loss: 0.0278 - val_acc: 0.9921\n",
      "Epoch 545/600\n",
      "33600/33600 [==============================] - 64s 2ms/step - loss: 0.0172 - acc: 0.9948 - val_loss: 0.0305 - val_acc: 0.9923\n",
      "Epoch 546/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0174 - acc: 0.9949 - val_loss: 0.0309 - val_acc: 0.9921\n",
      "Epoch 547/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0175 - acc: 0.9943 - val_loss: 0.0258 - val_acc: 0.9932\n",
      "Epoch 548/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0184 - acc: 0.9947 - val_loss: 0.0277 - val_acc: 0.9924\n",
      "Epoch 549/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0178 - acc: 0.9944 - val_loss: 0.0281 - val_acc: 0.9927\n",
      "Epoch 550/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0172 - acc: 0.9943 - val_loss: 0.0312 - val_acc: 0.9926\n",
      "Epoch 551/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0187 - acc: 0.9940 - val_loss: 0.0280 - val_acc: 0.9930\n",
      "Epoch 552/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0166 - acc: 0.9947 - val_loss: 0.0280 - val_acc: 0.9932\n",
      "Epoch 553/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0169 - acc: 0.9946 - val_loss: 0.0288 - val_acc: 0.9929\n",
      "Epoch 554/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0188 - acc: 0.9945 - val_loss: 0.0321 - val_acc: 0.9929\n",
      "Epoch 555/600\n",
      "33600/33600 [==============================] - 64s 2ms/step - loss: 0.0182 - acc: 0.9940 - val_loss: 0.0276 - val_acc: 0.9932\n",
      "Epoch 556/600\n",
      "33600/33600 [==============================] - 65s 2ms/step - loss: 0.0147 - acc: 0.9949 - val_loss: 0.0278 - val_acc: 0.9938\n",
      "Epoch 557/600\n",
      "33600/33600 [==============================] - 68s 2ms/step - loss: 0.0198 - acc: 0.9941 - val_loss: 0.0298 - val_acc: 0.9929\n",
      "Epoch 558/600\n",
      "33600/33600 [==============================] - 73s 2ms/step - loss: 0.0167 - acc: 0.9949 - val_loss: 0.0293 - val_acc: 0.9929\n",
      "Epoch 559/600\n",
      "33600/33600 [==============================] - 96s 3ms/step - loss: 0.0170 - acc: 0.9944 - val_loss: 0.0278 - val_acc: 0.9937\n",
      "Epoch 560/600\n",
      "33600/33600 [==============================] - 131s 4ms/step - loss: 0.0196 - acc: 0.9938 - val_loss: 0.0327 - val_acc: 0.9921\n",
      "Epoch 561/600\n",
      "33600/33600 [==============================] - 129s 4ms/step - loss: 0.0172 - acc: 0.9950 - val_loss: 0.0292 - val_acc: 0.9932\n",
      "Epoch 562/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0187 - acc: 0.9939 - val_loss: 0.0285 - val_acc: 0.9929\n",
      "Epoch 563/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0177 - acc: 0.9946 - val_loss: 0.0271 - val_acc: 0.9927\n",
      "Epoch 564/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0209 - acc: 0.9932 - val_loss: 0.0302 - val_acc: 0.9926\n",
      "Epoch 565/600\n",
      "33600/33600 [==============================] - 131s 4ms/step - loss: 0.0159 - acc: 0.9946 - val_loss: 0.0306 - val_acc: 0.9925\n",
      "Epoch 566/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0177 - acc: 0.9941 - val_loss: 0.0320 - val_acc: 0.9920\n",
      "Epoch 567/600\n",
      "33600/33600 [==============================] - 129s 4ms/step - loss: 0.0177 - acc: 0.9943 - val_loss: 0.0273 - val_acc: 0.9927\n",
      "Epoch 568/600\n",
      "33600/33600 [==============================] - 129s 4ms/step - loss: 0.0178 - acc: 0.9943 - val_loss: 0.0316 - val_acc: 0.9923\n",
      "Epoch 569/600\n",
      "33600/33600 [==============================] - 129s 4ms/step - loss: 0.0183 - acc: 0.9943 - val_loss: 0.0296 - val_acc: 0.9929\n",
      "Epoch 570/600\n",
      "33600/33600 [==============================] - 129s 4ms/step - loss: 0.0207 - acc: 0.9937 - val_loss: 0.0262 - val_acc: 0.9935\n",
      "Epoch 571/600\n",
      "33600/33600 [==============================] - 128s 4ms/step - loss: 0.0166 - acc: 0.9948 - val_loss: 0.0261 - val_acc: 0.9930\n",
      "Epoch 572/600\n",
      "33600/33600 [==============================] - 129s 4ms/step - loss: 0.0162 - acc: 0.9947 - val_loss: 0.0321 - val_acc: 0.9920\n",
      "Epoch 573/600\n",
      "33600/33600 [==============================] - 129s 4ms/step - loss: 0.0162 - acc: 0.9946 - val_loss: 0.0301 - val_acc: 0.9925\n",
      "Epoch 574/600\n",
      "33600/33600 [==============================] - 128s 4ms/step - loss: 0.0164 - acc: 0.9949 - val_loss: 0.0272 - val_acc: 0.9933\n",
      "Epoch 575/600\n",
      "33600/33600 [==============================] - 129s 4ms/step - loss: 0.0171 - acc: 0.9945 - val_loss: 0.0320 - val_acc: 0.9924\n",
      "Epoch 576/600\n",
      "33600/33600 [==============================] - 129s 4ms/step - loss: 0.0164 - acc: 0.9944 - val_loss: 0.0302 - val_acc: 0.9926\n",
      "Epoch 577/600\n",
      "33600/33600 [==============================] - 128s 4ms/step - loss: 0.0173 - acc: 0.9944 - val_loss: 0.0265 - val_acc: 0.9933\n",
      "Epoch 578/600\n",
      "33600/33600 [==============================] - 129s 4ms/step - loss: 0.0179 - acc: 0.9945 - val_loss: 0.0292 - val_acc: 0.9926\n",
      "Epoch 579/600\n",
      "33600/33600 [==============================] - 129s 4ms/step - loss: 0.0175 - acc: 0.9942 - val_loss: 0.0295 - val_acc: 0.9927\n",
      "Epoch 580/600\n",
      "33600/33600 [==============================] - 129s 4ms/step - loss: 0.0180 - acc: 0.9940 - val_loss: 0.0334 - val_acc: 0.9923\n",
      "Epoch 581/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 129s 4ms/step - loss: 0.0173 - acc: 0.9944 - val_loss: 0.0286 - val_acc: 0.9929\n",
      "Epoch 582/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0175 - acc: 0.9944 - val_loss: 0.0362 - val_acc: 0.9919\n",
      "Epoch 583/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0165 - acc: 0.9949 - val_loss: 0.0284 - val_acc: 0.9923\n",
      "Epoch 584/600\n",
      "33600/33600 [==============================] - 130s 4ms/step - loss: 0.0160 - acc: 0.9953 - val_loss: 0.0276 - val_acc: 0.9930\n",
      "Epoch 585/600\n",
      "33536/33600 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9943"
     ]
    }
   ],
   "source": [
    "# 7. Fit model on training data\n",
    "history = model.fit(X_train, y_train_cat, validation_data=(X_test, y_test_cat), \n",
    "                    epochs=600, \n",
    "                    batch_size=128, \n",
    "                    #callbacks=callbacks_list, \n",
    "                    verbose =1)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "plt.plot(train_loss, label='Training loss')\n",
    "plt.plot(test_loss, label='Testing loss')\n",
    "#plt.xticks(history.epoch)\n",
    "plt.title('Loss')\n",
    "plt.grid()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "#plt.xticks(history.epoch)\n",
    "plt.xlim()\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(np.argmax(y_test_cat,axis=1),model.predict_classes(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(np.argmax(y_test_cat,axis=1),model.predict_classes(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_predicts = model.predict_classes(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df= pd.DataFrame(val_predicts)\n",
    "df['ImageId'] = df.index+1\n",
    "df.columns=['Label','ImageId']\n",
    "df = df[['ImageId','Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('Digit Recog Predicts_mix_2', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kay = pd.read_csv('Digit Recog Predicts_mix_2')\n",
    "kay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#|0.9235| loss: 1.0872 - val_loss: 0.4303 @ adam = .01, 2convo - d - hid(128) - d - out\n",
    "#|bad   | loss: bad - val_loss: bad @ adam = .01, 2convo - d - hid(128)(l2=0.001) - d - hid2(128) - out\n",
    "\n",
    "#|0.9235| loss: 1.0872 - val_loss: 0.4303 @ adam = .01, 2convo - hid(128) - d - hid2(128) - d - out\n",
    "#|0.9556| loss: 0.5472 - val_loss: 0.1765 @ adam = .01, 2convo - hid(128) - d - hid2(128) - d - hid3(128) - out\n",
    "\n",
    "#|0.9812| loss: 0.1270 - val_loss: 0.0645 @ 2convo - hid(128) - d(0.5) - hid(128) - d(0.5) - hid2(128) - out\n",
    "#|0.9814| loss: 0.1216 - val_loss: 0.0775 @ 2convo - hid(256) - d(0.5) - hid(128) - d(0.5) - hid2(128) - out\n",
    "#|0.9828| loss: 0.1230 - val_loss: 0.0627 @ 2convo - hid(256) - d(0.5) - hid(256) - d(0.5) - hid2(128) - out(5epoch)\n",
    "\n",
    "#|0.9816| loss: 0.1051 - val_loss: 0.0680 @ 2convo - hid(256) - d(0.4) - hid(256) - d(0.4) - hid2(128) - out(5epoch)\n",
    "#|0.9816| loss: 0.1005 - val_loss: 0.0630 @ 2convo - hid(256) - d(0.3) - hid(256) - d(0.4) - hid2(128) - out(4epoch)\n",
    "#|0.9843| loss: 0.0751 - val_loss: 0.0627 @ 2convo - hid(256) - d(0.25) - hid(256) - d(0.3) - hid2(128) - out(7ish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#|0.9878| loss: 0.1508 - acc: 0.9586 - val_loss: 0.0489 - val_acc: 0.9852 \n",
    "#convo(.25)convo(.25) - hid(528) - d(0.25) - hid(256) - d(0.25) - hid2(128)- out\n",
    "#~70 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss: 0.1034 - acc: 0.9701 - val_loss: 0.0440 - val_acc: 0.9881\n",
    "#convo(.25)convo(.25) - hid(508) - d(0.2) - hid(256) - d(0.2) - hid2(128)- out\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss: 0.0847 - acc: 0.9752 - val_loss: 0.0527 - val_acc: 0.9840\n",
    "#convo[5x5](k32)(.25)-convo[3x3](k16)(.25) - hid(528) - d(0.2) - hid(256) - d(0.2) - hid2(128)- out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#97.8\n",
    "#convo[5x5](k32)(same)(.25)-convo[5x5](k16)(.25)-convo[3x3](same)(k8)(.25) - \n",
    "#hid(528) - d(0.2) - hid(256) - d(0.2) - hid2(128)- out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#96\n",
    "#convo[5x5](k32)(.25)-convo[5x5](k16)(.25)-convo[3x3](k8)(.25) - \n",
    "#hid(528) - d(0.2) - hid(256) - d(0.2) - hid2(128)- out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#.990: 5533 & .15\n",
    "\n",
    "#.992 : 553 & .2\n",
    "# : 553 & .25\n",
    "\n",
    "#.990 : 533 & .15\n",
    "\n",
    "#.990 : 533 & .25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.99226190476190479\n",
    "#553 & .2\n",
    "\n",
    "adam = optimizers.Adam(lr=0.005)\n",
    "l2 = regularizers.l2(0.1)\n",
    "\n",
    "# 5. Model Architecture\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(filters = 32, \n",
    "                        kernel_size = 5,\n",
    "                       activation = 'relu', \n",
    "                        input_shape = (28,28,1)))\n",
    "model.add(Convolution2D(filters = 32, \n",
    "                        kernel_size = 5,\n",
    "                        padding = 'same',\n",
    "                       activation = 'relu',\n",
    "                        input_shape = (28,28,1)))\n",
    "model.add(MaxPooling2D( pool_size= (2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Convolution2D(filters = 8, \n",
    "                        kernel_size = 3,\n",
    "                        padding = 'same',\n",
    "                       activation = 'relu'))\n",
    "model.add(Convolution2D(filters = 8, \n",
    "                        kernel_size = 3,\n",
    "                        padding = 'same',\n",
    "                       activation = 'relu'))\n",
    "model.add(MaxPooling2D( pool_size= (2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(256, \n",
    "                activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(128, \n",
    "                activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.99011904761904757\n",
    "#533 & .25\n",
    "\n",
    "adam = optimizers.Adam(lr=0.005)\n",
    "l2 = regularizers.l2(0.1)\n",
    "\n",
    "# 5. Model Architecture\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(filters = 32, \n",
    "                        kernel_size = 5,\n",
    "                       activation = 'relu', \n",
    "                        input_shape = (28,28,1)))\n",
    "model.add(Convolution2D(filters = 16, \n",
    "                        kernel_size = 3,\n",
    "                        padding = 'same',\n",
    "                       activation = 'relu',\n",
    "                        input_shape = (28,28,1)))\n",
    "model.add(MaxPooling2D( pool_size= (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Convolution2D(filters = 8, \n",
    "                        kernel_size = 3,\n",
    "                        padding = 'same',\n",
    "                       activation = 'relu'))\n",
    "model.add(Convolution2D(filters = 8, \n",
    "                        kernel_size = 3,\n",
    "                        padding = 'same',\n",
    "                       activation = 'relu'))\n",
    "model.add(MaxPooling2D( pool_size= (2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(256, \n",
    "                activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(128, \n",
    "                activation='relu'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
